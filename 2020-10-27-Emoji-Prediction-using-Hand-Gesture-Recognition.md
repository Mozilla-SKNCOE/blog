#Emoji-Prediction-using-Hand-Gesture-Recognition
<h1>Emoji Prediction Using Hand Gesture Recognition</h1>
<h2>Author: Tanmay Shinde<h2>
<p>This article illustrates the topic Emoji Prediction Using Hand Gesture Recognition in detail. In this project the basic ideology is to train a AI model in such a way that it should be able to predict the emoji which is made by the hand in front of the camera. There is an optimal requirement for this project , it consist of working OS system which can be laptop or computer and a web cam or inbuild camera would also work. </p><br></br>
<p>The motivation of this project is as now-a-days the usage of emojis in conversation is increasing and itâ€™s use makes the chat more interesting. But sometimes a problem arises like users need to search for their desired emojis in the chat keyboard. So with the help of this project, the users will be able to use their required emojis without the need of glancing through the list of emojis present. So this has certain advantages such as the chatting speed would gradually increase, the stress of finding the required emoji would be drastically reduced and the use of emoji would be fun for user as the process of emoji prediction would be user friendly and interesting. </p><br></br>
<p>There are 3 major modules in this project namely Background Substraction, Motion Detection and Training the Model. In the module of Background Substraction, as the name suggest in this process the background is being substracted from the foreground of the image. The main goal here is to obtain foreground image which is the object. The technique used here is The running gauge average, where the system is made to go through a round of almost 30 frames and after that computation is carried out over the current frame and the previous frames. After doing this process the system is familier with the background and now if we bring the hand in front of camera then the system would be able to guess the hand by croping out the background and providing us with the object as output. </p><br></br>
<p>The next module is about the motion detection one of the basic functions of motion detection framework is the capability to record video when a moving object is detected in the field of view of the camera. his helps reduce the storage required for saving the video, as it is recorded only when motion is detected by the camera. Furthermore, motion detection allows for quickly summarizing and reviewing the activity in a scene to identify unusual events or security breaches. The implemented framework makes use of the neural responses in a Gaussian mixture model (NeRM) framework for modeling of the background in scenes and then in detection of moving objects, which can be carried out or is feasible on embedded systems. The proposed NeRM method uses the advantage of sparse synaptic connectivity(s) and does the resolving of computational complexity of running a deep neural network on embedded systems also keeping up with maintenance of its performance and accuracy.</p><br></br>
<p>Training the model is the module in which the model is been trained using CNN (Convolution Neural Network), we can train the dataset of hand gestures and convolution is the first layer to extract features from an input image. Convolution preserves the relationship between pixels by learning image features using small grids of input data. Convolution is a mathematical operation that takes two inputs. The 2 inputs are: Image matrix and filter. Convolutional neural system (ConvNets or CNNs) is one of the primary classifications to do pictures acknowledgment, pictures orders. Items location, acknowledgment faces and so on, are a portion of the regions where CNNs are broadly utilized. CNN image classification takes an info picture, processes it and categorizes it under specific classifications.</p><br></br>
<p>We have demonstrated the feasibility of using CNN (Convolutional Neural Network) for feature extraction and is one of the most accurate ways for precise gesture recognition. The demonstration has focused on TWO elements: First is about the common observable properties that are associated with neural activity play a direct and obvious role in our capacity to recognize gestures under our method. Second, that it maintains that the central challenge with our method is the accuracy and consistency of the results. </p><br></br>
